{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze hub genes and high-weight edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hub gene analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtain the gene connectivity matrix (for each cell type, there are five degree matrices, one for each fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../get_degree_matrix_train.py -expr ../../data/pre_data/scRNAseq_datasets/AMB.npz \\\n",
    "    -outdir ../../result/ \\\n",
    "    -ca 0.01 -hvgs 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the hub genes for each cell type for the five folds (100 genes for each fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "seq_dict = np.load('../../result/datasets/AMB/seq_dict.npz', allow_pickle=True) \n",
    "label = seq_dict['label']\n",
    "\n",
    "matrix_dict = np.load('../../result/datasets/AMB/degree_matrix_train_AMB_a0.01_hvgs2000.npz', allow_pickle=True)\n",
    "\n",
    "print(\"Keys in loaded matrix_dict:\", matrix_dict.files)\n",
    "str_labels = matrix_dict['str_labels']\n",
    "print(\"cell-type: \", str_labels)\n",
    "\n",
    "print(\"Length of str_labels:\", len(str_labels))\n",
    "\n",
    "for k in range(len(str_labels)):\n",
    "    degree_matrix_key = f'{k}' \n",
    "    degree_matrix_dict = matrix_dict[degree_matrix_key].item()  \n",
    "    print(degree_matrix_dict.keys())\n",
    "    fold_top_indices_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(5):\n",
    "        fold = i + 1\n",
    "        cur_fold_degree_matrix = degree_matrix_dict[f'CV_{fold}']\n",
    "        mean_degree = np.mean(cur_fold_degree_matrix, axis=1)\n",
    "        top_100_indices = np.argsort(mean_degree)[-100:][::-1] \n",
    "        fold_top_indices_df[f'Fold_{fold}'] = top_100_indices\n",
    "\n",
    "    cell_type_name = str_labels[k]\n",
    "    os.makedirs(\"data/AMB/Gene_degree\",exist_ok=True)\n",
    "    tsv_filename = f'data/AMB/Gene_degree/{cell_type_name}_top100_indices.tsv'\n",
    "    fold_top_indices_df.to_csv(tsv_filename, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"Saved top 100 indices for cell type '{cell_type_name}' to {tsv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtain the union of hub genes for each cell type to get the charactersit gene set for each cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_and_union_tsv(cell_type):\n",
    "\n",
    "    file_path = f'data/AMB/Gene_degree/{cell_type}_top100_indices.tsv'\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(file_path, sep='\\t')\n",
    "        union_set = set()\n",
    "        for col in data.columns:\n",
    "            union_set.update(data[col].dropna().astype(int))\n",
    "        \n",
    "        return list(union_set)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found for cell type {cell_type}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cell_type}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_cell_types(str_labels):\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    for cell_type in str_labels:\n",
    "        union_genes = read_and_union_tsv(cell_type)\n",
    "        result_dict[cell_type] = pd.Series(union_genes, dtype='Int64')\n",
    "        print(f\"{cell_type}: {len(union_genes)} genes\")\n",
    "    \n",
    "    result_df = pd.DataFrame(result_dict)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "seq_dict = np.load('../../result/datasets/AMB/seq_dict.npz', allow_pickle=True) \n",
    "str_labels = seq_dict['str_labels']\n",
    "\n",
    "result_df = process_cell_types(str_labels)\n",
    "\n",
    "output_path = 'data/AMB/AMB_character_gene_set_indices.tsv'\n",
    "result_df.to_csv(output_path, sep='\\t', index=False)\n",
    "print(f\"\\nResults saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the gene symbols corresponding to the 2000 HVGs (Highly Variable Genes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict = np.load('../../result/datasets/AMB/seq_dict.npz', allow_pickle=True) \n",
    "genes = seq_dict['gene_symbol']\n",
    "\n",
    "all_filtered_genes_file = '../../result/datasets/AMB/AMB_filtered_hvgs2000.npy'\n",
    "\n",
    "all_filtered_genes_array = np.load(all_filtered_genes_file, allow_pickle=True)\n",
    "filtered_genes_index = all_filtered_genes_array[0]\n",
    "filtered_genes_index = filtered_genes_index.astype(int)\n",
    "print(filtered_genes_index.shape)\n",
    "\n",
    "filtered_genes = genes[filtered_genes_index]\n",
    "\n",
    "print(filtered_genes)\n",
    "print(filtered_genes.shape)\n",
    "df = pd.DataFrame(filtered_genes, columns=['gene_symbol'])\n",
    "df.to_csv('data/AMB/AMB_gene_symbol_hvgs2000.tsv',  sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on the gene symbols obtained above, convert the indices in the character gene set to the corresponding gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/AMB/AMB_character_gene_set_indices.tsv'\n",
    "gene_idx_df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "gene_symbol_file = 'data/AMB/AMB_gene_symbol_hvgs2000.tsv'\n",
    "gene_symbol = pd.read_csv(gene_symbol_file, sep='\\t')\n",
    "gene_symbol_dict = {i: gene_symbol.iloc[i, 0] for i in range(len(gene_symbol))}\n",
    "\n",
    "def map_to_gene_symbol(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    return gene_symbol_dict.get(int(value), None)\n",
    "\n",
    "gene_idx_df = gene_idx_df.applymap(map_to_gene_symbol)\n",
    "\n",
    "output_file_path = 'data/AMB/AMB_character_gene_set.tsv'\n",
    "gene_idx_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Save to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hub gene Plot: R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript Figure-AMB-gene.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of highly correlated gene pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtain the top 100 high-weight edges (gene pairs) for each cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from scipy import sparse\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_top_edges(matrices, top_k=100):\n",
    "\n",
    "    total_matrices = len(matrices)  \n",
    "    edge_weights = defaultdict(float)\n",
    "    \n",
    "    for matrix in matrices:\n",
    "        rows, cols = matrix.nonzero()\n",
    "        values = matrix.data\n",
    "\n",
    "        for i in range(len(rows)):\n",
    "            node1 = int(min(rows[i], cols[i]))\n",
    "            node2 = int(max(rows[i], cols[i]))\n",
    "            if node1 != node2:  \n",
    "                edge_weights[(node1, node2)] += float(values[i])\n",
    "    edge_avg_weights = []\n",
    "    for (node1, node2), weight_sum in edge_weights.items():\n",
    "        avg_weight = float(weight_sum) / float(total_matrices)\n",
    "        edge_avg_weights.append((int(node1), int(node2), float(avg_weight)))\n",
    "\n",
    "    return heapq.nlargest(top_k, edge_avg_weights, key=lambda x: x[2])\n",
    "\n",
    "\n",
    "def load_and_process_matrices(cell_test_folder, cur_label_idxs):\n",
    "\n",
    "    matrices = []\n",
    "\n",
    "    for idx in cur_label_idxs:\n",
    "        data = torch.load(os.path.join(cell_test_folder, f'cell_{idx}.pt'))\n",
    "        edge_index = data.edge_index\n",
    "        edge_weight = data.edge_weight\n",
    "        \n",
    "        num_nodes = data.x.shape[0] \n",
    "        edges = edge_index.cpu().numpy()\n",
    "        weights = edge_weight.cpu().numpy()\n",
    "\n",
    "        sparse_mat = sparse.csr_matrix(\n",
    "            (weights, (edges[0], edges[1])),\n",
    "            shape=(num_nodes, num_nodes)\n",
    "        )           \n",
    "      \n",
    "        matrices.append(sparse_mat)     \n",
    "    \n",
    "    return matrices\n",
    "    \n",
    "\n",
    "def save_cell_type_edges(cell_type, fold_edges, save_folder, base_filename):\n",
    "\n",
    "    save_dir = os.path.join(save_folder, f\"{base_filename}_edges\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    filename = os.path.join(save_dir, f\"{cell_type}_top_edges.npz\")\n",
    "    \n",
    "    save_dict = {\n",
    "        'cell_type': cell_type,\n",
    "        'base_filename': base_filename\n",
    "    }\n",
    "    \n",
    "    for fold_idx, edges in fold_edges.items():\n",
    "        edges_array = np.array(edges, dtype=[\n",
    "            ('node1', 'int32'), \n",
    "            ('node2', 'int32'), \n",
    "            ('weight', 'float32')\n",
    "        ])\n",
    "        save_dict[f'fold_{fold_idx}_edges'] = edges_array        \n",
    "    \n",
    "    np.savez(filename, **save_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict = np.load('../../result/datasets/AMB/seq_dict.npz', allow_pickle=True) \n",
    "label = seq_dict['label'] \n",
    "str_labels = seq_dict['str_labels']\n",
    "save_folder = 'data/AMB/Edge_weight'\n",
    "\n",
    "cell_type_edges = {}\n",
    "\n",
    "for cur_label, cell_type in enumerate(str_labels):\n",
    "    print(\"cur_label: \", cur_label)\n",
    "    print(\"cell_type: \", cell_type)\n",
    "\n",
    "    fold_edges = {}\n",
    "    \n",
    "    for k in range(5):\n",
    "        k_fold = k + 1\n",
    "        train_index = seq_dict[f'train_index_{k_fold}']\n",
    "        label_train = label[train_index]\n",
    "        cur_label_idxs = np.where(label_train == cur_label)[0].tolist()\n",
    "\n",
    "\n",
    "        cell_train_folder = os.path.join(\n",
    "            \"../../result/datasets/AMB/wcsn_a0.01_hvgs2000\", \n",
    "            f\"train_f{k_fold}\", \n",
    "            'processed'\n",
    "        )\n",
    "        \n",
    "        cur_mat = load_and_process_matrices(cell_train_folder, cur_label_idxs)\n",
    "        cur_top_edges = find_top_edges(cur_mat)\n",
    "\n",
    "        fold_edges[k_fold] = cur_top_edges\n",
    "\n",
    "    save_cell_type_edges(cell_type, fold_edges, save_folder,  base_filename=\"AMB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def create_edge_strings(edges):\n",
    "    return [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "\n",
    "def process_npz_file(file_path):\n",
    "    cell_type = os.path.basename(file_path).replace('_top_edges.npz', '')\n",
    "    \n",
    "    output_dir = os.path.join('data/AMB/Edge_weight', f'{cell_type}_top_edges')\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    try:\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "        for i in range(1, 6):  \n",
    "            fold_key = f'fold_{i}_edges'\n",
    "            if fold_key in data:\n",
    "                edges = data[fold_key]\n",
    "                edge_strings = create_edge_strings(edges)\n",
    "                \n",
    "                output_file = os.path.join(output_dir, f'fold_{i}_edges.csv')\n",
    "                pd.DataFrame({'edges': edge_strings}).to_csv(output_file, index=False)\n",
    "                \n",
    "        print(f\"Successfully processed {cell_type}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cell_type}: {str(e)}\")\n",
    "\n",
    "def process_all_cell_types(base_dir):\n",
    "\n",
    "    npz_files = glob.glob(os.path.join(base_dir, '*_top_edges.npz'))\n",
    "    \n",
    "    if not npz_files:\n",
    "        print(f\"No npz files found in {base_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(npz_files)} files to process\")\n",
    "    \n",
    "    for file_path in npz_files:\n",
    "        process_npz_file(file_path)\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "base_dir = 'data/AMB/Edge_weight/AMB_edges'\n",
    "process_all_cell_types(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtain the union of highly correlated gene pairs for each cell type to get the characterist edge set for each cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_union_edges(npz_file):\n",
    "   data = np.load(npz_file, allow_pickle=True)\n",
    "   all_edges = set()\n",
    "   \n",
    "   for i in range(1, 6):\n",
    "       fold_key = f'fold_{i}_edges'\n",
    "       if fold_key in data:\n",
    "           edges = data[fold_key]\n",
    "           edge_strings = [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "           all_edges.update(edge_strings)\n",
    "   print(list(all_edges))\n",
    "   return sorted(list(all_edges)) \n",
    "\n",
    "\n",
    "seq_dict = np.load('../../result/datasets/AMB/seq_dict.npz', allow_pickle=True) \n",
    "str_labels = seq_dict['str_labels']\n",
    "\n",
    "cell_types = str_labels.tolist()  \n",
    "print(\"cell types: \", cell_types)\n",
    "\n",
    "edges_dict = {}\n",
    "\n",
    "for cell_type in cell_types:\n",
    "   npz_file = f'data/AMB/Edge_weight/AMB_edges/{cell_type}_top_edges.npz' \n",
    "   if os.path.exists(npz_file):\n",
    "        edges_dict[cell_type] = get_union_edges(npz_file)\n",
    "\n",
    "max_length = max(len(edges) for edges in edges_dict.values())\n",
    "\n",
    "for cell_type in edges_dict:\n",
    "   if len(edges_dict[cell_type]) < max_length:\n",
    "       edges_dict[cell_type].extend([''] * (max_length - len(edges_dict[cell_type])))\n",
    "\n",
    "df = pd.DataFrame(edges_dict)\n",
    "print(df.columns)\n",
    "\n",
    "save_path = 'data/AMB/AMB_character_edge_set_indices.tsv'\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Save successfully: {save_path}\")\n",
    "\n",
    "print(\"\\n The number of different cell types\")\n",
    "\n",
    "for cell_type in cell_types:\n",
    "   edge_count = len([x for x in edges_dict[cell_type] if x != ''])\n",
    "   print(f\"{cell_type}: {edge_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert the indices in the character edge set file obtained above to the corresponding gene pair gene symbols and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_symbol_file = 'data/AMB/AMB_gene_symbol_hvgs2000.tsv'\n",
    "gene_symbol = pd.read_csv(gene_symbol_file, sep='\\t')\n",
    "\n",
    "gene_symbol_dict = {i: gene_symbol.iloc[i, 0] for i in range(len(gene_symbol))}\n",
    "\n",
    "file_path = 'data/AMB/AMB_character_edge_set_indices.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "def convert_edges_to_gene_symbols(edge_str):\n",
    "    if pd.isna(edge_str):\n",
    "        return None\n",
    "    gene1, gene2 = edge_str.split('-')\n",
    "    gene1_symbol = gene_symbol_dict.get(int(gene1), 'Unknown')\n",
    "    gene2_symbol = gene_symbol_dict.get(int(gene2), 'Unknown')\n",
    "    return f\"{gene1_symbol}-{gene2_symbol}\"\n",
    "\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(convert_edges_to_gene_symbols)\n",
    "\n",
    "save_path = 'data/AMB/AMB_character_edge_set.tsv'\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Save to: {save_path}\")\n",
    "\n",
    "print(\"\\n The number of different cell types\")\n",
    "for column in df.columns:\n",
    "    edge_count = df[column].apply(lambda x: x != '').sum()\n",
    "    print(f\"{column}: {edge_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot highly correlated gene pairs: R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript Figure-AMB-edge.R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38tor112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
